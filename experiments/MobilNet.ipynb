{
 "cells": [
  {
   "metadata": {
    "id": "f01bd44caa886fe8"
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models"
   ],
   "id": "f01bd44caa886fe8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "e2e774652cb7af75"
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.optim import lr_scheduler"
   ],
   "id": "e2e774652cb7af75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "10b5054c4633076c",
    "outputId": "d3291ce3-6c7b-4c43-ebe0-917fd5005329"
   },
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "checkpoint_path = \"/content/drive/My Drive/mobilnet_224.pth\"\n",
    "metrics_path = \"/content/drive/My Drive/training_metrics_mobilnet_224.json\"\n",
    "\n"
   ],
   "id": "10b5054c4633076c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "data_dir = '/content/drive/My Drive/data/classification/dataset_CIFAR10.zip'\n",
    "!mkdir /content/dataset/\n",
    "!unzip \"/content/drive/My Drive/data/classification/dataset_CIFAR10.zip\" -d \"/content/dataset/\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0am7DpK2gaUd",
    "outputId": "ae6e108c-2fe9-4926-84d6-0ff3882feaec"
   },
   "id": "0am7DpK2gaUd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "40dc4d571abe34e"
   },
   "cell_type": "code",
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=\"/content/dataset/train\", transform=train_transform)\n",
    "test_dataset = datasets.ImageFolder(root=\"/content/dataset/validation\", transform=test_transform)\n"
   ],
   "id": "40dc4d571abe34e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e45e13b04bb6a23f",
    "outputId": "19a9d0a0-5457-4ed6-c5f2-b36b0a5dd24e"
   },
   "cell_type": "code",
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(train_dataset.classes)\n",
    "print(device)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "id": "e45e13b04bb6a23f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "dfba1fb9f0f3df9a"
   },
   "cell_type": "code",
   "source": [
    "def train_iteration(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    average_loss = 0\n",
    "    average_accuracy = 0\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(images)\n",
    "        loss = loss_fn(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        average_loss += loss.item()\n",
    "        average_accuracy += (predictions.argmax(1) == labels).type(torch.float).sum().item()\n",
    "\n",
    "    average_loss /= len(dataloader)\n",
    "    average_accuracy /= size\n",
    "    return {'average_loss': average_loss, 'average_accuracy': average_accuracy}\n",
    "\n",
    "def test_iteration(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    average_loss = 0\n",
    "    average_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            predictions = model(images)\n",
    "            average_loss += loss_fn(predictions, labels).item()\n",
    "            average_accuracy += (predictions.argmax(1) == labels).type(torch.float).sum().item()\n",
    "    average_loss /= num_batches\n",
    "    average_accuracy /= size\n",
    "    return {'average_loss': average_loss, 'average_accuracy': average_accuracy}"
   ],
   "id": "dfba1fb9f0f3df9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4154b21bcd312c37",
    "outputId": "cf28c753-bf99-4294-e282-4abe1428654b"
   },
   "cell_type": "code",
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', weights=models.MobileNet_V2_Weights.DEFAULT)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(train_dataset.classes))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer_ft.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    exp_lr_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    print(f\"Resuming training from epoch {start_epoch}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No checkpoint found. Starting training from scratch.\")\n",
    "    start_epoch = 0"
   ],
   "id": "4154b21bcd312c37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "ae993809b7c4b431"
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "def save_metrics(epoch, train_results, test_results, filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        metrics = []\n",
    "\n",
    "    metrics.append({\n",
    "        'epoch': epoch + 1,\n",
    "        'train_loss': train_results['average_loss'],\n",
    "        'train_accuracy': train_results['average_accuracy'],\n",
    "        'test_loss': test_results['average_loss'],\n",
    "        'test_accuracy': test_results['average_accuracy']\n",
    "    })\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(metrics, f, indent=4)"
   ],
   "id": "ae993809b7c4b431",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "aeeb22086e4c2197",
    "outputId": "6da2e1db-9439-4b8f-dd8c-edf53d26affe"
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 60\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train_results = train_iteration(train_loader, model, criterion, optimizer_ft)\n",
    "    test_results = test_iteration(test_loader, model, criterion)\n",
    "    save_metrics(epoch, train_results, test_results, metrics_path)\n",
    "    print(f\"Metrics saved to {metrics_path}\")\n",
    "    print(f\"Train Loss: {train_results['average_loss']}, Train Accuracy: {train_results['average_accuracy']}\")\n",
    "    print(f\"Test Loss: {test_results['average_loss']}, Test Accuracy: {test_results['average_accuracy']}\")\n",
    "    # Save model state after each epoch\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer_ft.state_dict(),\n",
    "        'scheduler_state_dict': exp_lr_scheduler.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "print(\"Finished Training\")"
   ],
   "id": "aeeb22086e4c2197",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "9df622d47558a41f"
   },
   "cell_type": "code",
   "source": [],
   "id": "9df622d47558a41f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
