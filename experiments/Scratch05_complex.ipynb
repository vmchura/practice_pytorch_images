{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import zipfile\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset"
   ],
   "id": "f01bd44caa886fe8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "checkpoint_path = '/home/vmchura/data/009.ImageProcessing/model_checkpoint_scratch_05_complex.pth'\n",
    "metrics_path = \"/home/vmchura/data/009.ImageProcessing/training_metrics_scratch_05_complex.json\"\n"
   ],
   "id": "10b5054c4633076c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=\"/home/vmchura/data/009.ImageProcessing/dataset_CIFAR10/train\", transform=train_transform)\n",
    "test_dataset = datasets.ImageFolder(root=\"/home/vmchura/data/009.ImageProcessing/dataset_CIFAR10/validation\", transform=test_transform)\n"
   ],
   "id": "40dc4d571abe34e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ImageClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 4 * 4, 1024)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(self.relu2(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(self.relu3(self.bn3(self.conv3(x))))\n",
    "        x = self.pool4(self.relu4(self.bn4(self.conv4(x))))\n",
    "\n",
    "        x = x.view(-1, 512 * 4 * 4)\n",
    "\n",
    "        x = self.dropout1(self.relu5(self.fc1(x)))\n",
    "        x = self.dropout2(self.relu6(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def predict(self, x):\n",
    "        return torch.softmax(self.forward(x), dim=1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(train_dataset.classes)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "id": "e45e13b04bb6a23f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_iteration(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    average_loss = 0\n",
    "    average_accuracy = 0\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(images)\n",
    "        loss = loss_fn(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        average_loss += loss.item()\n",
    "        average_accuracy += (predictions.argmax(1) == labels).type(torch.float).sum().item()\n",
    "\n",
    "    average_loss /= len(dataloader)\n",
    "    average_accuracy /= size\n",
    "    return {'average_loss': average_loss, 'average_accuracy': average_accuracy}\n",
    "\n",
    "def test_iteration(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    average_loss = 0\n",
    "    average_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            predictions = model(images)\n",
    "            average_loss += loss_fn(predictions, labels).item()\n",
    "            average_accuracy += (predictions.argmax(1) == labels).type(torch.float).sum().item()\n",
    "    average_loss /= num_batches\n",
    "    average_accuracy /= size\n",
    "    return {'average_loss': average_loss, 'average_accuracy': average_accuracy}"
   ],
   "id": "dfba1fb9f0f3df9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = ImageClassifier(num_classes=len(train_dataset.classes)).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    print(f\"Resuming training from epoch {start_epoch}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No checkpoint found. Starting training from scratch.\")\n",
    "    start_epoch = 0"
   ],
   "id": "4154b21bcd312c37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "def save_metrics(epoch, train_results, test_results, filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        metrics = []\n",
    "\n",
    "    metrics.append({\n",
    "        'epoch': epoch + 1,\n",
    "        'train_loss': train_results['average_loss'],\n",
    "        'train_accuracy': train_results['average_accuracy'],\n",
    "        'test_loss': test_results['average_loss'],\n",
    "        'test_accuracy': test_results['average_accuracy']\n",
    "    })\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(metrics, f, indent=4)"
   ],
   "id": "ae993809b7c4b431",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_epochs = 60\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train_results = train_iteration(train_loader, model, criterion, optimizer)\n",
    "    test_results = test_iteration(test_loader, model, criterion)\n",
    "    save_metrics(epoch, train_results, test_results, metrics_path)\n",
    "    print(\"Metrics saved to training_metrics_scratch_05_complex.json\")\n",
    "    print(f\"Train Loss: {train_results['average_loss']}, Train Accuracy: {train_results['average_accuracy']}\")\n",
    "    print(f\"Test Loss: {test_results['average_loss']}, Test Accuracy: {test_results['average_accuracy']}\")\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "print(\"Finished Training\")"
   ],
   "id": "aeeb22086e4c2197",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9df622d47558a41f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
