{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "71ojRN6RWRGP"
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import zipfile\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from torch.optim import lr_scheduler"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "checkpoint_path = \"/content/drive/My Drive/mobilnet_full.pth\"\n",
    "metrics_path = \"/content/drive/My Drive/training_metrics_mobilnet_full.json\"\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MViQVJJtWlmz",
    "outputId": "05b2127a-23e6-453b-f41b-1365926b6f10"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "data_dir = '/content/drive/My Drive/data/classification/dataset_CIFAR10.zip'\n",
    "!mkdir /content/dataset/\n",
    "!unzip \"/content/drive/My Drive/data/classification/dataset_CIFAR10.zip\" -d \"/content/dataset/\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nNtmSMK-XBy9",
    "outputId": "4564a1af-52fb-48e0-9f81-afd1b495b38c"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(72),\n",
    "    transforms.RandomCrop(64),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=\"/content/dataset/train\", transform=train_transform)\n",
    "test_dataset = datasets.ImageFolder(root=\"/content/dataset/validation\", transform=test_transform)\n"
   ],
   "metadata": {
    "id": "p7SdlDymXIl4"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(train_dataset.classes)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1BMVgdpXTDe",
    "outputId": "1af9dce9-61f7-4f94-c190-ab9813798b44"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def train_iteration(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(images)\n",
    "        loss = loss_fn(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "          print(f\"loss: {loss.item():>4f}\")\n",
    "\n",
    "\n",
    "\n",
    "    return None\n",
    "\n",
    "def test_iteration(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    average_loss = 0\n",
    "    average_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            predictions = model(images)\n",
    "            average_loss += loss_fn(predictions, labels).item()\n",
    "            average_accuracy += (predictions.argmax(1) == labels).type(torch.float).sum().item()\n",
    "    average_loss /= num_batches\n",
    "    average_accuracy /= size\n",
    "    return {'average_loss': average_loss, 'average_accuracy': average_accuracy}"
   ],
   "metadata": {
    "id": "lC8bNaEQXUtm"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', weights=models.MobileNet_V2_Weights.DEFAULT)\n",
    "\n",
    "model.classifier[1] = nn.Sequential(\n",
    "    nn.Linear(model.classifier[1].in_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(512, len(train_dataset.classes))\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.002, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer_ft.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    exp_lr_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    print(f\"Resuming training from epoch {start_epoch}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No checkpoint found. Starting training from scratch.\")\n",
    "    start_epoch = 0"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cXSAD_1CXW6Z",
    "outputId": "f2b111f2-91e5-4915-bf77-8b10bebb4a14"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "def save_metrics(epoch, train_results, test_results, filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        metrics = []\n",
    "\n",
    "    metrics.append({\n",
    "        'epoch': epoch + 1,\n",
    "        'train_loss': train_results['average_loss'],\n",
    "        'train_accuracy': train_results['average_accuracy'],\n",
    "        'test_loss': test_results['average_loss'],\n",
    "        'test_accuracy': test_results['average_accuracy']\n",
    "    })\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(metrics, f, indent=4)"
   ],
   "metadata": {
    "id": "UKZe_rpbXZCT"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "num_epochs = 60\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    _ = train_iteration(train_loader, model, criterion, optimizer_ft)\n",
    "    train_results = test_iteration(train_loader, model, criterion)\n",
    "    test_results = test_iteration(test_loader, model, criterion)\n",
    "    save_metrics(epoch, train_results, test_results, metrics_path)\n",
    "    print(f\"Metrics saved to {metrics_path}\")\n",
    "    print(f\"Train Loss: {train_results['average_loss']}, Train Accuracy: {train_results['average_accuracy']}\")\n",
    "    print(f\"Test Loss: {test_results['average_loss']}, Test Accuracy: {test_results['average_accuracy']}\")\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer_ft.state_dict(),\n",
    "        'scheduler_state_dict': exp_lr_scheduler.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "print(\"Finished Training\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZbjYhrfBXawH",
    "outputId": "ef9575e9-1dd8-4eaa-9ab2-67909c59811b"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "a3jL4mxeXimx"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
